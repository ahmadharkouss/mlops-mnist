networks:
  monitoring:
    driver: bridge
    name: monitoring
volumes:
  prometheus_data: {}
  grafana_data: {}
  alertmanager-data: {}

services:
  #node-exporter:
  #  image: prom/node-exporter:latest
  #  container_name: node-exporter
  #  restart: unless-stopped
  #  volumes:
  #    - /proc:/host/proc:ro
  #    - /sys:/host/sys:ro
  #    - /:/rootfs:ro
  #  command:
  #   - '--path.procfs=/host/proc'
  #    - '--path.rootfs=/rootfs'
  #    - '--path.sysfs=/host/sys'
  #    - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
  #  ports:
  #    - 9200:9200
  # networks:
  #    - monitoring

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    volumes:
      - ./prometheus:/etc/prometheus/
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - 9090:9090
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager:latest
    restart: unless-stopped
    container_name: alertmgr
    ports:
      - "9093:9093"
    volumes:
      - "./alertmanager:/config"
      - alertmanager-data:/data
    command: --config.file=/config/alertmanager.yml --log.level=debug
    networks:
      - monitoring
 
  blackbox:
    image: prom/blackbox-exporter:latest
    # privileged: true
    restart: unless-stopped
    container_name: blackbox
    volumes:
      - ./blackbox/blackbox.yml:/etc/blackbox_exporter/config.yml
    ports:
      - '9115:9115'
    networks:
      - monitoring
      
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    user: '0'
    ports:
      - 3000:3000
    restart: unless-stopped
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GF_SECURITY_ADMIN_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GF_SECURITY_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=${GF_USERS_ALLOW_SIGN_UP}
    networks:
      - monitoring
    
  otel-collector:
    container_name: otel-collector
    image: otel/opentelemetry-collector-contrib
    volumes:
      - ./otel-collector/otel-collector-config.yaml:/etc/otelcol-contrib/config.yaml
    ports:
      #- 1888:1888 # pprof extension
      #- 8888:8888 # Prometheus metrics exposed by the Collector
      #- 8889:8889 # Prometheus exporter metrics
      #- 13133:13133 # health_check extension
      - 4321:4321 # OTLP gRPC receiver
      - 4319:4319 # OTLP http receiver
      #- 55679:55679 # zpages extension
    networks:
      - monitoring
  loki:
    image: grafana/loki:2.9.2
    container_name: loki
    command: ["-config.file=/etc/loki/loki.yaml"]
    volumes:
      - "./loki/loki.yaml:/etc/loki/loki.yaml"
    ports:
      - "3100:3100"
    networks:
      - monitoring

  #promtail:
  #  image: grafana/promtail:2.9.2
  #  container_name: promtail
  #  volumes:
  #    - /var/log:/var/log
  #  command: -config.file=/etc/promtail/config.yml
  #  networks:
  #    - monitoring


  # Tempo runs as user 10001, and docker compose creates the volume as root.
  # As such, we need to chown the volume in order for Tempo to start correctly.
  init:
    image: &tempoImage grafana/tempo:latest
    user: root
    entrypoint:
      - "chown"
      - "10001:10001"
      - "/var/tempo"
    volumes:
      - ./tempo-data:/var/tempo

  tempo:
    image: *tempoImage
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./tempo/tempo.yaml:/etc/tempo.yaml
      - ./tempo-data:/var/tempo
    ports:
      - "14268"  # jaeger ingest
      - "3200"   # tempo
      - "4317"  # otlp grpc
      - "4318"  # otlp http
      - "9411"   # zipkin
    depends_on:
      - init
    networks:
      - monitoring  
  